{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the pipeline of phenotype analysis\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import tree_util\n",
    "from pyseat.SEAT import SEAT\n",
    "import warnings\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def sort_rule(x):\n",
    "    x = x['name']\n",
    "    if ( '--' in x) or ('__' in x):\n",
    "        return x\n",
    "\n",
    "    if 'C' in x:\n",
    "        numx = int(x.split('C')[-1])\n",
    "    else:\n",
    "        numx = int(x.split('S')[-1])\n",
    "    return numx\n",
    "\n",
    "\n",
    "#    seat = tree_util.make_tree(net_df)\n",
    "\n",
    "def pre_process(df_norm, tlevel):\n",
    "    if '{}__'.format(tlevel) in df_norm.index:\n",
    "        df_norm.drop('{}__'.format(tlevel), axis=0, inplace=True)\n",
    "        df_norm.drop('{}__'.format(tlevel), axis=1, inplace=True)\n",
    "    df_norm = df_norm.rename(index=lambda x: x.replace(' ', '-'))\n",
    "    df_norm = df_norm.rename(columns=lambda x: x.replace(' ', '-'))\n",
    "    df_norm = df_norm.loc[:, (df_norm != 0).any(axis=0)]\n",
    "    df_norm = df_norm.loc[(df_norm != 0).any(axis=1), :]\n",
    "    return df_norm\n",
    "\n",
    "\n",
    "def post_process(df, seat, outdir):\n",
    "    newick_tree = seat.newick\n",
    "    subroot_nodes = seat.se_tree.optimal_subpopulation_node_ids\n",
    "    json_tree = tree_util.parse(newick_tree)\n",
    "\n",
    "    parent_dict = {}\n",
    "    tree_util.parents(json_tree, parent_dict)\n",
    "    parent_dict_int = {}\n",
    "    for key, value in parent_dict.items():\n",
    "        if value == '':\n",
    "            continue\n",
    "        key_new = int(key[1:])\n",
    "        parent_dict_int[key_new] = int(value[1:])\n",
    "\n",
    "    conpact_children_dict = {'root': subroot_nodes}\n",
    "    for lid in seat.leaves_list:\n",
    "        conpact_children_dict[lid] = []\n",
    "        first_pid = parent_dict_int[lid]\n",
    "        if first_pid not in conpact_children_dict.keys():\n",
    "            conpact_children_dict[first_pid] = []\n",
    "        conpact_children_dict[first_pid].append(lid)\n",
    "        if first_pid in subroot_nodes:\n",
    "            continue\n",
    "        # find subpopulation\n",
    "        current_aid = first_pid\n",
    "        while current_aid not in subroot_nodes:\n",
    "            current_aid = parent_dict_int[current_aid]\n",
    "        if current_aid not in conpact_children_dict.keys():\n",
    "            conpact_children_dict[current_aid] = []\n",
    "        if first_pid not in conpact_children_dict[current_aid]:\n",
    "            conpact_children_dict[current_aid].append(first_pid)\n",
    "\n",
    "    compact_json = tree_util.call_tree(conpact_children_dict, 'root')\n",
    "\n",
    "    # rename leaves as species name\n",
    "    name_dict, reverse_dict = tree_util.name_reflection(df)\n",
    "    tree_util.rename_node(compact_json, reverse_dict)\n",
    "    newick_tree = tree_util.call_newick(compact_json)\n",
    "    newick_tree = newick_tree.replace('_', '-')\n",
    "\n",
    "    with open(os.path.join(outdir, 'tree.newick'), 'w') as fp:\n",
    "        fp.write(newick_tree)\n",
    "\n",
    "    json_tree =tree_util.parse(newick_tree)\n",
    "    largest = {'largest': 0}\n",
    "    leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "    largest_level = largest['largest']\n",
    "    nlayer = largest_level\n",
    "    layer_leaves_dict = tree_util.make_layer_dict(nlayer)\n",
    "    tree_util.recu_layer(json_tree, layer_leaves_dict)\n",
    "    tree_util.to_layer_leaves(layer_leaves_dict, nlayer)\n",
    "\n",
    "    parent_dict = {}\n",
    "    tree_util.parents(json_tree, parent_dict)\n",
    "    node_leaves = {}\n",
    "    for level in layer_leaves_dict.keys():\n",
    "        for node, sp_list in layer_leaves_dict[level].items():\n",
    "            if node in node_leaves.keys():\n",
    "                continue\n",
    "            node_leaves[node] = copy.deepcopy(sp_list)\n",
    "\n",
    "    direct_children_dict = {}\n",
    "    for node, parent in parent_dict.items():\n",
    "        if parent not in direct_children_dict:\n",
    "            direct_children_dict[parent] = []\n",
    "        direct_children_dict[parent].append(node)\n",
    "\n",
    "    leaves_num = pd.DataFrame(columns=['num'], index=list(node_leaves.keys()))\n",
    "    for k, v in node_leaves.items():\n",
    "        leaves_num.loc[k, 'num'] = len(v)\n",
    "\n",
    "    leaves_num = leaves_num.sort_values(by='num', ascending=False)\n",
    "\n",
    "    c_tmp_short = 'cluster_C{}'\n",
    "    c_tmp = 'cluster_S{}-C{}'\n",
    "    sc_tmp = 'supercluster_S{}'\n",
    "    # sort and rename supercluster and cluster\n",
    "    rename_df = pd.DataFrame(columns=['class', 'leaves n', 'parent_name', 'alias', 'parent_alias']) # name is the index\n",
    "    rename_df.loc['nroot', ] = ['root', len(reverse_dict.keys()), 'NA', 'root', 'NA']\n",
    "    internal_rename_dict = {'nroot': 'root'}\n",
    "    supclusters = []\n",
    "    leaf_set = set(leaf_list)\n",
    "\n",
    "    children = direct_children_dict['nroot']\n",
    "    selected_num = leaves_num.loc[children, ]\n",
    "    selected_num = selected_num.sort_values(by='num', ascending=False)\n",
    "    i = 0\n",
    "    for c in selected_num.index:\n",
    "        i += 1\n",
    "        cchildren = direct_children_dict[c]\n",
    "        if not set(cchildren).issubset(leaf_set):\n",
    "            # is a supercluster\n",
    "            parent = parent_dict[c]\n",
    "            supclusters.append(c)\n",
    "            internal_rename_dict[c] = sc_tmp.format(i)\n",
    "            rename_df.loc[c, ] = ['supercluster', leaves_num.loc[c, 'num'], parent, internal_rename_dict[c], internal_rename_dict[parent]]\n",
    "        else:\n",
    "            parent = parent_dict[c]\n",
    "            internal_rename_dict[c] = c_tmp_short.format(i)\n",
    "            rename_df.loc[c, ] = ['cluster', leaves_num.loc[c, 'num'], parent, internal_rename_dict[c], internal_rename_dict[parent]]\n",
    "\n",
    "\n",
    "    for node in supclusters:\n",
    "        children = direct_children_dict[node]\n",
    "        selected_num = leaves_num.loc[children, ]\n",
    "        selected_num = selected_num.sort_values(by='num', ascending=False)\n",
    "        i = 0\n",
    "        for c in selected_num.index:\n",
    "            if not c.startswith('n'):\n",
    "                continue\n",
    "            i += 1\n",
    "            \n",
    "            parent = parent_dict[c]\n",
    "            parent_alias = internal_rename_dict[parent]\n",
    "            digit = parent_alias[14:]\n",
    "            internal_rename_dict[c] = c_tmp.format(digit, i)\n",
    "            rename_df.loc[c, ] = ['cluster', leaves_num.loc[c, 'num'], parent, internal_rename_dict[c], parent_alias]\n",
    "\n",
    "    rename_df = rename_df.sort_values(by = 'leaves n', ascending=False)\n",
    "    rename_df.to_csv(os.path.join(outdir, 'node_rename.tsv'), sep='\\t')\n",
    "\n",
    "    # rename the cluster and supercluster\n",
    "    renamed_json_tree = copy.deepcopy(json_tree)\n",
    "    tree_util.rename_node(renamed_json_tree, internal_rename_dict)\n",
    "    tree_util.sort_children(renamed_json_tree, sort_rule)\n",
    "    newick = tree_util.call_newick(renamed_json_tree)\n",
    "    with open(os.path.join(outdir, 'renamed_GCN_tree.newick'), 'w') as fp:\n",
    "        fp.write(newick)\n",
    "    internal_newick = tree_util.call_internal_tree(renamed_json_tree, set(leaf_list))\n",
    "    with open(os.path.join(outdir, 'internal_tree.newick'), 'w') as fp:\n",
    "        fp.write(internal_newick)\n",
    "\n",
    "    df = pd.DataFrame(columns=['species', 'cluster', 'supercluster'], index=[x.replace('-', '_') for x in leaf_list])\n",
    "    df.fillna('NA', inplace=True)\n",
    "    for k, leaves in node_leaves.items():\n",
    "        k = rename_df.loc[k, 'alias']\n",
    "        cluster_id = k.split('_')[-1] \n",
    "        contents = cluster_id.split('-')\n",
    "        for l in leaves:\n",
    "            l = l.replace('-', '_')\n",
    "            if contents[-1][0] == 'C':\n",
    "                df.loc[l, 'cluster'] = cluster_id.replace('-', '_')\n",
    "            if contents[-1][0] == 'S':\n",
    "                df.loc[l, 'supercluster'] = contents[-1].replace('-', '_')\n",
    "            if contents[0][0] == 'S':\n",
    "                if (df.loc[l, 'supercluster'] != 'NA') and (df.loc[l, 'supercluster'] !=contents[0]):\n",
    "                    print(l, df.loc[l, 'supercluster'])\n",
    "                df.loc[l, 'supercluster'] = contents[0].replace('-', '_')\n",
    "\n",
    "    df['species'] = df.index\n",
    "    df.sort_values(by=['supercluster', 'cluster']).to_csv(os.path.join(outdir, 'leaves_cluster.tsv'), sep='\\t', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tlevel = 'g'\n",
    "indir = '../result/S1_plasmid_net/feature'\n",
    "outdir = '../result/S1_plasmid_net/tree'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "ipath = os.path.join(indir, 'log_rescale.tsv')\n",
    "df = pd.read_csv(ipath, sep='\\t', index_col=0)\n",
    "df_norm = pre_process(df, tlevel)\n",
    "df_norm.to_csv(os.path.join(outdir, 'log_rescale.tsv'), sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "odir = os.path.join(outdir, 'log_rescale', 'gksb')\n",
    "if not os.path.exists(odir):\n",
    "    os.makedirs(odir)\n",
    "seat = SEAT(affinity=\"gaussian_kernel\",\n",
    "            sparsification=\"knn_neighbors\",\n",
    "            objective=\"SE\",\n",
    "            strategy=\"bottom_up\")\n",
    "seat.fit(df_norm)\n",
    "post_process(df_norm, seat, odir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
